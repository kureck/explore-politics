{"paragraphs":[{"text":"%pyspark\nimport nltk\nfrom nltk.corpus import stopwords\nfrom string import punctuation\nfrom pyspark.sql.functions import col\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nnltk.download('stopwords')\n\ndf = spark.read.json('s3://kureck/discourse/file.json')\nstopwords_pt = set(stopwords.words('portuguese') + list(punctuation))","dateUpdated":"2018-04-26T20:26:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[nltk_data] Downloading package stopwords to\n[nltk_data]     /var/lib/zeppelin/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n"}]},"apps":[],"jobName":"paragraph_1524774364571_-1304444987","id":"20180426-142441_1796123821","dateCreated":"2018-04-26T20:26:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:269","user":"anonymous","dateFinished":"2018-04-26T20:27:47+0000","dateStarted":"2018-04-26T20:26:31+0000"},{"text":"%pyspark\n#sample = df.sample(True, 0.2, 42)\n\n#sample.coalesce(1).write.format('json').save('s3://kureck/discourse/sample.json')","user":"anonymous","dateUpdated":"2018-04-26T20:32:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524774458273_-968235745","id":"20180426-202738_686186273","dateCreated":"2018-04-26T20:27:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:982","dateFinished":"2018-04-26T20:32:34+0000","dateStarted":"2018-04-26T20:32:04+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\ndf = df.na.drop(subset=['party'])\n\ntokenizer = Tokenizer(inputCol=\"discourse\", outputCol=\"words\")\n\nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(list(stopwords_pt))\n\ncountVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n\nlabel_stringIdx = StringIndexer(inputCol=\"party\", outputCol=\"label\")","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1524774364579_-1319834943","id":"20180426-155504_563914104","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:270"},{"text":"%pyspark\nstages = [tokenizer, stopwordsRemover, countVectors, label_stringIdx]\npipeline = Pipeline(stages=stages)\n\nprint(\"Pipeline fit...\")\npipelineFit = pipeline.fit(df)\n\nprint(\"Pipeline transform...\")\ndataset = pipelineFit.transform(df)\ndataset.show(5)\n\nprint(\"Splitting in training and test dataset...\")\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Pipeline fit...\nPipeline transform...\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n|               date|           discourse|party|       speaker|                 url|               words|            filtered|            features|label|\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n|31/10/2000 14:02:00|O SR. SIMÃO SESSI...|  PPB|  SIMÃO SESSIM|http://www.camara...|[o, sr., simão, s...|[sr., simão, sess...|(10000,[0,1,2,3,5...| 18.0|\n|31/10/2000 14:04:00|O SR. EDUARDO JOR...|   PT| EDUARDO JORGE|http://www.camara...|[o, sr., eduardo,...|[sr., eduardo, jo...|(10000,[0,1,2,3,4...|  0.0|\n|31/10/2000 14:12:00|O SR. BABÁ (PT-PA...|   PT|          BABÁ|http://www.camara...|[o, sr., babá, (p...|[sr., babá, (pt-p...|(10000,[0,1,2,3,4...|  0.0|\n|31/10/2000 14:24:00|O SR. CARLOS MOSC...| PSDB|CARLOS MOSCONI|http://www.camara...|[o, sr., carlos, ...|[sr., carlos, mos...|(10000,[0,1,3,4,9...|  2.0|\n|31/10/2000 14:36:00|O SR. EDINHO BEZ ...| PMDB|    EDINHO BEZ|http://www.camara...|[o, sr., edinho, ...|[sr., edinho, bez...|(10000,[0,1,2,3,9...|  1.0|\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\nonly showing top 5 rows\n\nSplitting in training and test dataset...\n"}]},"apps":[],"jobName":"paragraph_1524774364580_-1321758688","id":"20180426-155622_126081548","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:271"},{"text":"%pyspark\nprint(\"Applying logistic regression...\")\nlr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nlrModel = lr.fit(trainingData)\n\nprint(\"Making predicions...\")\npredictions = lrModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"discourse\", \"party\", \"probability\", \"label\", \"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n=10, truncate=30)\n\nprint(\"Evaluating model...\")\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nprint(evaluator.evaluate(predictions))","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Pipeline fit...\nPipeline transform...\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n|               date|           discourse|party|       speaker|                 url|               words|            filtered|            features|label|\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\n|31/10/2000 14:02:00|O SR. SIMÃO SESSI...|  PPB|  SIMÃO SESSIM|http://www.camara...|[o, sr., simão, s...|[sr., simão, sess...|(10000,[0,1,2,3,5...| 18.0|\n|31/10/2000 14:04:00|O SR. EDUARDO JOR...|   PT| EDUARDO JORGE|http://www.camara...|[o, sr., eduardo,...|[sr., eduardo, jo...|(10000,[0,1,2,3,4...|  0.0|\n|31/10/2000 14:12:00|O SR. BABÁ (PT-PA...|   PT|          BABÁ|http://www.camara...|[o, sr., babá, (p...|[sr., babá, (pt-p...|(10000,[0,1,2,3,4...|  0.0|\n|31/10/2000 14:24:00|O SR. CARLOS MOSC...| PSDB|CARLOS MOSCONI|http://www.camara...|[o, sr., carlos, ...|[sr., carlos, mos...|(10000,[0,1,3,4,9...|  2.0|\n|31/10/2000 14:36:00|O SR. EDINHO BEZ ...| PMDB|    EDINHO BEZ|http://www.camara...|[o, sr., edinho, ...|[sr., edinho, bez...|(10000,[0,1,2,3,9...|  1.0|\n+-------------------+--------------------+-----+--------------+--------------------+--------------------+--------------------+--------------------+-----+\nonly showing top 5 rows\n\nSplitting in training and test dataset...\nApplying logistic regression...\nMaking predicions...\n+------------------------------+-----+------------------------------+-----+----------+\n|                     discourse|party|                   probability|label|prediction|\n+------------------------------+-----+------------------------------+-----+----------+\n|O SR. EUDES XAVIER (PT-CE. ...|   PT|[0.9999999918633603,4.33082...|  0.0|       0.0|\n|O SR. RICARDO BERZOINI (PT-...|   PT|[0.9999999786859017,3.63427...|  0.0|       0.0|\n|O SR. PAULO ROCHA (PT-PA. S...|   PT|[0.999999920977275,4.324138...|  0.0|       0.0|\n|O SR. SIBÁ MACHADO (PT-AC. ...|   PT|[0.9999994102794223,5.17886...|  0.0|       0.0|\n|O SR. JOSÉ GENOÍNO (PT-SP. ...|   PT|[0.9999991647514761,3.80605...|  0.0|       0.0|\n|O SR. VICENTINHO (PT-SP. Se...|   PT|[0.999985084367474,4.189403...|  0.0|       0.0|\n|         O SR. ANTONIO CARL...|  DEM|[0.9999845745370186,1.44544...|  5.0|       0.0|\n|O SR. CARLOS ABICALIL (PT-M...|   PT|[0.9999751526688005,1.09420...|  0.0|       0.0|\n|O SR. LUIZ COUTO (PT-PB. Se...|   PT|[0.9999669904583673,4.67911...|  0.0|       0.0|\n|O SR. LUIZ ALBERTO (PT-BA. ...|   PT|[0.999966602925735,6.542112...|  0.0|       0.0|\n+------------------------------+-----+------------------------------+-----+----------+\nonly showing top 10 rows\n\nEvaluating model...\n0.563154722481\n"}]},"apps":[],"jobName":"paragraph_1524774364580_-1321758688","id":"20180426-142455_1917927672","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:272"},{"text":"%pyspark\nfrom pyspark.ml.feature import HashingTF, IDF\nhashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n\npipeline = Pipeline(stages=[tokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n\nprint(\"Pipeline fit...\")\npipelineFit = pipeline.fit(df)\n\nprint(\"Pipeline transform...\")\ndataset = pipelineFit.transform(df)\n\nprint(\"Splitting in training and test dataset...\")\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n\nprint(\"Applying logistic regression...\")\nlr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\nlrModel = lr.fit(trainingData)\n\nprint(\"Making predicions...\")\npredictions = lrModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"discourse\", \"party\", \"probability\", \"label\", \"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nprint(\"Evaluating model...\")\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nprint(evaluator.evaluate(predictions))","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Pipeline fit...\nPipeline transform...\nSplitting in training and test dataset...\nApplying logistic regression...\nMaking predicions...\n+------------------------------+-----+------------------------------+-----+----------+\n|                     discourse|party|                   probability|label|prediction|\n+------------------------------+-----+------------------------------+-----+----------+\n|O SR. EUDES XAVIER (PT-CE. ...|   PT|[0.9999999987890318,1.15990...|  0.0|       0.0|\n|O SR. RICARDO BERZOINI (PT-...|   PT|[0.9999999961093722,1.00467...|  0.0|       0.0|\n|O SR. PAULO ROCHA (PT-PA. S...|   PT|[0.99999906766946,4.2198097...|  0.0|       0.0|\n|O SR. JOSÉ GENOÍNO (PT-SP. ...|   PT|[0.9999908798500585,5.39624...|  0.0|       0.0|\n|O SR. SIBÁ MACHADO (PT-AC. ...|   PT|[0.9999908144011388,1.99843...|  0.0|       0.0|\n|O SR. NAZARENO FONTELES (PT...|   PT|[0.9999717883629562,1.79752...|  0.0|       0.0|\n|O SR. EUDES XAVIER (PT-CE. ...|   PT|[0.9999713214079857,1.39091...|  0.0|       0.0|\n|O SR. VICENTINHO (PT-SP. Se...|   PT|[0.9999707704487208,1.95143...|  0.0|       0.0|\n|O SR. MARCO MAIA (PT-RS. Se...|   PT|[0.9999538077088573,9.02001...|  0.0|       0.0|\n|A SRA. FÁTIMA BEZERRA (PT-R...|   PT|[0.9999454177522477,1.88384...|  0.0|       0.0|\n+------------------------------+-----+------------------------------+-----+----------+\nonly showing top 10 rows\n\nEvaluating model...\n0.43933060228\n"}]},"apps":[],"jobName":"paragraph_1524774364581_-1322143437","id":"20180426-142615_389529474","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:273"},{"text":"%pyspark\n## With Cross-validation\npipeline = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors, label_stringIdx])\n\nprint(\"Pipeline fit...\")\npipelineFit = pipeline.fit(df)\n\nprint(\"Pipeline transform...\")\ndataset = pipelineFit.transform(df)\n\nprint(\"Splitting in training and test dataset...\")\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n\nprint(\"Applying logistic regression...\")\nlr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n             .build())\n# Create 5-fold CrossValidator\n\ncv = CrossValidator(estimator=lr, \\\n                    estimatorParamMaps=paramGrid, \\\n                    evaluator=MulticlassClassificationEvaluator(), \\\n                    numFolds=5)\nprint(\"Applying cross CrossValidator...\")\ncvModel = cv.fit(trainingData)\n\npredictions = cvModel.transform(testData)\n\n# Evaluate best model\nprint(\"Evaluating model...\")\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nprint(evaluator.evaluate(predictions))\n","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"msg":[{"type":"TEXT","data":""}]},"apps":[],"jobName":"paragraph_1524774364581_-1322143437","id":"20180426-144732_785478424","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:274"},{"text":"%pyspark\nfrom pyspark.ml.classification import NaiveBayes\n\nnb = NaiveBayes(smoothing=1)\nmodel = nb.fit(trainingData)\n\npredictions = model.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"discourse\", \"party\", \"probability\", \"label\", \"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------------------+-----+------------------------------+-----+----------+\n|                     discourse|party|                   probability|label|prediction|\n+------------------------------+-----+------------------------------+-----+----------+\n|O SR. JOSÉ GUIMARÃES (PT-CE...|   PT|[1.0,4.8144508668782255E-18...|  0.0|       0.0|\n|O SR. MAURO PEREIRA (PMDB-R...| PMDB|[1.0,1.1331685475847354E-18...|  1.0|       0.0|\n|O SR. ZÉ GERALDO (PT-PA. Se...|   PT|[1.0,6.846694773172001E-20,...|  0.0|       0.0|\n|O SR. MARCO MAIA (PT-RS. Se...|   PT|[1.0,4.954039182512548E-20,...|  0.0|       0.0|\n|O SR. DR. ROSINHA (PT-PR. S...|   PT|[1.0,1.625257369292623E-20,...|  0.0|       0.0|\n|O SR. BOHN GASS (PT-RS. Sem...|   PT|[1.0,1.0452516577782611E-20...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[1.0,1.0360065190608415E-20...|  0.0|       0.0|\n|O SR. LUIZ COUTO (PT-PB. Se...|   PT|[1.0,8.565963570826226E-21,...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[1.0,2.526637226586675E-21,...|  0.0|       0.0|\n|O SR. MARCON (PT-RS. Pela o...|   PT|[1.0,1.2733978132450254E-21...|  0.0|       0.0|\n+------------------------------+-----+------------------------------+-----+----------+\nonly showing top 10 rows\n\n0.4736222672223392\n"}]},"apps":[],"jobName":"paragraph_1524774364582_-1320989190","id":"20180426-161056_2015290410","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:275"},{"text":"%pyspark\n## Random Forest\nfrom pyspark.ml.classification import RandomForestClassifier\nrf = RandomForestClassifier(labelCol=\"label\", \\\n                            featuresCol=\"features\", \\\n                            numTrees = 100, \\\n                            maxDepth = 20, \\\n                            maxBins = 32)\n# Train model with Training Data\nrfModel = rf.fit(trainingData)\npredictions = rfModel.transform(testData)\npredictions.filter(predictions['prediction'] == 0) \\\n    .select(\"discourse\", \"party\", \"probability\", \"label\", \"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 10, truncate = 30)\n\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nevaluator.evaluate(predictions)","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------------------+-----+------------------------------+-----+----------+\n|                     discourse|party|                   probability|label|prediction|\n+------------------------------+-----+------------------------------+-----+----------+\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.6314606773266598,0.04444...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.6085644572391316,0.06024...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.5983610174155395,0.05298...|  0.0|       0.0|\n|O SR. TARCÍSIO ZIMMERMANN (...|   PT|[0.5970699922474408,0.05550...|  0.0|       0.0|\n|O SR. CAETANO (PT-BA. Sem r...|   PT|[0.5925044651934497,0.06777...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.5920973182272009,0.05665...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.5903001977566065,0.05441...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.5870548415774616,0.05607...|  0.0|       0.0|\n|O SR. VALMIR ASSUNÇÃO (PT-B...|   PT|[0.5815366000770784,0.06965...|  0.0|       0.0|\n|A SRA. BENEDITA DA SILVA (P...|   PT|[0.5788035902482451,0.06565...|  0.0|       0.0|\n+------------------------------+-----+------------------------------+-----+----------+\nonly showing top 10 rows\n\n0.4515220751704036\n"}]},"apps":[],"jobName":"paragraph_1524774364583_-1321373939","id":"20180426-161841_864820110","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"%pyspark\n## With Cross-validation\npipeline = Pipeline(stages=[tokenizer, stopwordsRemover, countVectors, label_stringIdx])\n\nprint(\"Pipeline fit...\")\npipelineFit = pipeline.fit(df)\n\nprint(\"Pipeline transform...\")\ndataset = pipelineFit.transform(df)\n\nprint(\"Splitting in training and test dataset...\")\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n\nprint(\"Applying random forest...\")\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.numTrees, [10, 50, 100]) # regularization parameter\n             .addGrid(rf.maxDepth, [2, 10, 20]) # Elastic Net Parameter (Ridge = 0)\n             .addGrid(rf.maxBins, [10, 20, 30]) # Elastic Net Parameter (Ridge = 0)\n#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n             .build())\n# Create 5-fold CrossValidator\n\ncv = CrossValidator(estimator=rf, \\\n                    estimatorParamMaps=paramGrid, \\\n                    evaluator=MulticlassClassificationEvaluator(), \\\n                    numFolds=5)\nprint(\"Applying cross CrossValidator...\")\ncvModel = cv.fit(trainingData)\n\npredictions = cvModel.transform(testData)\n\n# Evaluate best model\nprint(\"Evaluating model...\")\nevaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\nprint(evaluator.evaluate(predictions))","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524774364585_-1323682432","id":"20180426-160738_2017605846","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"text":"%pyspark\n","dateUpdated":"2018-04-26T20:26:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524774364586_-1322528186","id":"20180426-180005_67116722","dateCreated":"2018-04-26T20:26:04+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:278"}],"name":"discourse logistic regression","id":"2DEDG6K8T","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}